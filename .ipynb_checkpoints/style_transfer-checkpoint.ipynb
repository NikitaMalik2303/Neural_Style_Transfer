{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f1fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c34c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4 ---> [(None, None, None, 3)]\n",
      "block1_conv1 ---> (None, None, None, 64)\n",
      "block1_conv2 ---> (None, None, None, 64)\n",
      "block1_pool ---> (None, None, None, 64)\n",
      "block2_conv1 ---> (None, None, None, 128)\n",
      "block2_conv2 ---> (None, None, None, 128)\n",
      "block2_pool ---> (None, None, None, 128)\n",
      "block3_conv1 ---> (None, None, None, 256)\n",
      "block3_conv2 ---> (None, None, None, 256)\n",
      "block3_conv3 ---> (None, None, None, 256)\n",
      "block3_conv4 ---> (None, None, None, 256)\n",
      "block3_pool ---> (None, None, None, 256)\n",
      "block4_conv1 ---> (None, None, None, 512)\n",
      "block4_conv2 ---> (None, None, None, 512)\n",
      "block4_conv3 ---> (None, None, None, 512)\n",
      "block4_conv4 ---> (None, None, None, 512)\n",
      "block4_pool ---> (None, None, None, 512)\n",
      "block5_conv1 ---> (None, None, None, 512)\n",
      "block5_conv2 ---> (None, None, None, 512)\n",
      "block5_conv3 ---> (None, None, None, 512)\n",
      "block5_conv4 ---> (None, None, None, 512)\n",
      "block5_pool ---> (None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "vgg = tf.keras.applications.VGG19(include_top = False, weights = \"imagenet\")\n",
    "\n",
    "for layers in vgg.layers:\n",
    "    print(f\"{layers.name} ---> {layers.output_shape}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4411e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):\n",
    "    \n",
    "    gram_matrix = tf.linalg.einsum(\"bijc,bijd->bcd\", input_tensor, input_tensor)\n",
    "    gram_matrix = tf.expand_dims(gram_matrix, axis = 0)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    i_j = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
    "    gram_matrix = gram_matrix/i_j\n",
    "    \n",
    "    return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b22d09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "    vgg = tf.keras.applications.VGG19(include_top = False, weights = \"imagenet\")\n",
    "    vgg.trainable = False\n",
    "    content_layers = [\"block4_conv2\"]\n",
    "    style_layers = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \"block5_conv1\"]\n",
    "    content_output = vgg.get_layer(content_layers[0]).output\n",
    "    style_outputs = [vgg.get_layer(style).output for style in style_layers]\n",
    "    gram_style_output = [gram_matrix(style) for style in style_outputs]\n",
    "    \n",
    "    model = tf.keras.models.Model([vgg.input], [content_output, gram_style_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91685bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Machine Learning\\Machine Learning Projects\\Neural_Style_Transfer\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9428\\1865880093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcontent_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\examples\\style_images\\content1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcontent_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong Path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "# content_image = cv2.resize(cv2.imread(path + \"\\examples\\style_images\\content1\"), (256,256))\n",
    "# if content_image is None:\n",
    "#     print(\"Wrong Path\")\n",
    "# else:\n",
    "#     content_image = tf.image.convert_image_dtype(content_image, tf.float32)       \n",
    "\n",
    "style_image = cv2.resize(cv2.imread(\"..\\examples\\style_images\\starry-night\"), (256,256))\n",
    "if content_image is None:\n",
    "    print(\"Wrong Path\")\n",
    "else:\n",
    "    style_image = tf.image.convert_image_dtype(style_image, tf.float32)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(cv2.cvtColor(np.array(content_image), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(cv2.cvtColor(np.array(style_image), cv2.COLOR_BGR2RGB ))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19003091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(content_output, content_input, style_output, style_input):\n",
    "    \n",
    "    content_weight = 1e-2\n",
    "    style_weight = 1e-1\n",
    "    content_loss = tf.reduce_mean((content_output - content_input)**2)\n",
    "    style_loss = [tf.reduce_mean(output_ - input_)**2 for output_, input_ in zip(style_output, style_input)]\n",
    "    style_loss = tf.add_n(style_loss)\n",
    "    \n",
    "    total_loss = style_weight*style_loss + content_weight*content_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d068c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.01, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b793446",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9428\\2009162573.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontent_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstyle_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstyle_image\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content_image' is not defined"
     ]
    }
   ],
   "source": [
    "vgg = load_model()\n",
    "content_output = vgg(np.array([content_image*255]))[0]\n",
    "style_output = vgg(np.array([style_image*255]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(image, epoch):\n",
    "    with tf.GradientTape as tape:\n",
    "        output = vgg(image)\n",
    "        loss = cal_loss(output[0],content_image, output[1],style_image )\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    optimizer.apply_gradients([(gradient, image)])\n",
    "    image.assign(tf.clip_by_value(image, clip_value_min = 0.0, clip_value_max = 1.0))\n",
    "    \n",
    "    print(f\"epoch no. = {epoch} -----> loss = {loss}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "image = tf.image.convert_image_dtype(content_image, tf.float32)\n",
    "image = tf.Variable([image])\n",
    "for i in range(epoch):\n",
    "    training(image, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image*255\n",
    "image = np.array(image, dtype = tf.uint8)\n",
    "if np.ndim(image)>3:\n",
    "    assert image.shape[0] == 1\n",
    "    image = image[0]\n",
    "    \n",
    "image = PIL.Image.fromarray(image)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
